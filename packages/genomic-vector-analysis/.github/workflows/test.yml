name: Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [18.x, 20.x, 22.x]

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:unit

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-${{ matrix.node-version }}
          path: test-results/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run integration tests
        run: npm run test:integration
        timeout-minutes: 15

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: test-results/

  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run performance benchmarks
        run: npm run test:benchmark
        timeout-minutes: 30

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: test-results/

      - name: Comment benchmark results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('test-results/benchmarks.json', 'utf8'));

            const comment = `## Performance Benchmark Results

            | Metric | Value | Target | Status |
            |--------|-------|--------|--------|
            | Query Latency (p95) | ${results.queryLatencyP95}ms | <1ms | ${results.queryLatencyP95 < 1 ? '✅' : '❌'} |
            | Throughput | ${results.throughput} var/sec | >50,000 | ${results.throughput > 50000 ? '✅' : '❌'} |
            | Memory Usage | ${results.memoryGB}GB | <100GB | ${results.memoryGB < 100 ? '✅' : '❌'} |
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests with coverage
        run: npm run test:coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          flags: unittests
          name: genomic-vector-analysis

      - name: Check coverage thresholds
        run: |
          node -e "
          const coverage = require('./coverage/coverage-summary.json');
          const total = coverage.total;

          const thresholds = {
            statements: 90,
            branches: 85,
            functions: 90,
            lines: 90
          };

          let failed = false;
          for (const [key, threshold] of Object.entries(thresholds)) {
            const pct = total[key].pct;
            if (pct < threshold) {
              console.error(\`❌ ${key} coverage (${pct}%) below threshold (${threshold}%)\`);
              failed = true;
            } else {
              console.log(\`✅ ${key} coverage (${pct}%) meets threshold (${threshold}%)\`);
            }
          }

          if (failed) {
            process.exit(1);
          }
          "

  validation-tests:
    name: Data Validation Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run validation tests
        run: npm run test:validation

      - name: Upload validation results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: validation-results
          path: test-results/

  rust-benchmarks:
    name: Rust Performance Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true

      - name: Run Criterion benchmarks
        run: cargo bench --manifest-path=rust/Cargo.toml
        working-directory: ./

      - name: Upload Criterion results
        uses: actions/upload-artifact@v4
        with:
          name: rust-benchmark-results
          path: target/criterion/

  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, coverage, validation-tests]
    if: always()

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-test-results

      - name: Generate summary report
        run: |
          echo "# Test Suite Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Unit Tests: Completed" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Integration Tests: Completed" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Performance Tests: Completed" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Validation Tests: Completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See artifacts for detailed reports." >> $GITHUB_STEP_SUMMARY

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            all-test-results/**/junit.xml
